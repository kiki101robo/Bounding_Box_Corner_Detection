{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Kirti Kishore\n",
        "\n",
        "UID: 120148286\n",
        "\n",
        "email: kiki1@umd.edu\n",
        "\n",
        "ENPM673 Project 2 Part 1\n",
        "\n",
        "Disclaimer: Please upload the video in the colab file before running this program. As well as change the name of the video file I have given in this program to whatever may the name be in your local environment."
      ],
      "metadata": {
        "id": "RvXog9UIpZUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Block 1: Importing Libraries"
      ],
      "metadata": {
        "id": "RywDSJMzoS-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flbtEYbk2GG4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This block imports the necessary libraries for computer vision and array manipulation."
      ],
      "metadata": {
        "id": "EgMLr3jHoO1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2: Video and Output Setup"
      ],
      "metadata": {
        "id": "3Nu1rWZaoafJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = 'proj2_v2.mp4'\n",
        "output_directory = 'frames'\n",
        "os.makedirs(output_directory, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "FPvIQhH2oYQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This block defines the path to the input video file and creates a directory to store extracted frames.\n",
        "\n",
        "Block 3: Output Video Parameters"
      ],
      "metadata": {
        "id": "ZAo3iv3DodLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_video_path = 'output_video.mp4'\n",
        "fps_output = 5\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')"
      ],
      "metadata": {
        "id": "qvrn2Ovwokep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: These parameters define the output video file path, desired frames per second (fps), and the video codec (XVID).\n",
        "\n",
        "Block 4: Video Capture and Frame Information"
      ],
      "metadata": {
        "id": "m4ObaA3WommZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "fps_input = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n"
      ],
      "metadata": {
        "id": "0ZghaTjRoqHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This block initializes a VideoCapture object, retrieves the input video's frames per second and total number of frames.\n",
        "\n",
        "Block 5: Image Processing Parameters"
      ],
      "metadata": {
        "id": "kxBlKNvwot9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laplacian_threshold = 150\n",
        "rho = 1\n",
        "theta = np.pi / 180\n",
        "threshold_hough = 100\n",
        "min_line_length = 100\n",
        "max_lines = 5\n",
        "roi_x_min, roi_x_max, roi_y_min, roi_y_max = 100, 500, 100, 700\n"
      ],
      "metadata": {
        "id": "t0n-GtZaovEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: These parameters include the Laplacian threshold, Hough Transform parameters, line length, maximum number of lines, and the region of interest (ROI).\n",
        "\n",
        "Block 6: Laplacian Kernel and Floodfill Parameters"
      ],
      "metadata": {
        "id": "DwNOYDmIoz-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laplacian_kernel = np.array([[0, 1, 0],\n",
        "                             [1, -4, 1],\n",
        "                             [0, 1, 0]])\n",
        "floodfill_seed_point = (roi_x_min + (roi_x_max - roi_x_min) // 2, roi_y_min + (roi_y_max - roi_y_min) // 2)\n",
        "floodfill_lo_diff = 30\n",
        "floodfill_up_diff = 30\n"
      ],
      "metadata": {
        "id": "muDzVCj9o4Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This block defines the Laplacian kernel and parameters for floodfill, including seed point and color differences.\n",
        "\n",
        "Block 7: Video Writer Setup"
      ],
      "metadata": {
        "id": "nTC_EZ3go6T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = cv2.VideoWriter(output_video_path, fourcc, fps_output, (int(cap.get(3)), int(cap.get(4))))\n"
      ],
      "metadata": {
        "id": "Mm9T8FJUo9UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This block initializes a VideoWriter object with the specified output file, codec, output fps, and frame size.\n",
        "\n",
        "Block 8: Main Loop for Processing Frames"
      ],
      "metadata": {
        "id": "Hphv05AvpB7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_connected_components(binary_image):\n",
        "    labeled_image = np.zeros_like(binary_image)\n",
        "    label_count = 1\n",
        "\n",
        "    def dfs(x, y, label):\n",
        "        if x < 0 or y < 0 or x >= binary_image.shape[1] or y >= binary_image.shape[0]:\n",
        "            return\n",
        "        if binary_image[y, x] == 1 and labeled_image[y, x] == 0:\n",
        "            labeled_image[y, x] = label\n",
        "            dfs(x + 1, y, label)\n",
        "            dfs(x - 1, y, label)\n",
        "            dfs(x, y + 1, label)\n",
        "            dfs(x, y - 1, label)\n",
        "\n",
        "    for y in range(binary_image.shape[0]):\n",
        "        for x in range(binary_image.shape[1]):\n",
        "            if binary_image[y, x] == 1 and labeled_image[y, x] == 0:\n",
        "                dfs(x, y, label_count)\n",
        "                label_count += 1\n",
        "\n",
        "    return labeled_image, label_count\n",
        "\n",
        "\n",
        "for frame_number in range(total_frames):\n",
        "    # Read the frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame was read successfully\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute the custom Laplacian using convolution\n",
        "    laplacian_output = cv2.filter2D(gray_frame, cv2.CV_64F, laplacian_kernel)\n",
        "\n",
        "    # Compute the variance of the custom Laplacian\n",
        "    laplacian_var = np.var(laplacian_output)\n",
        "\n",
        "    # Skip frames that have variance below the threshold\n",
        "    if laplacian_var < laplacian_threshold:\n",
        "        continue\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray_frame, 50, 150)\n",
        "\n",
        "    # Use Harris corner detector to detect corners in the image\n",
        "    corners = cv2.cornerHarris(gray_frame, 2, 3, 0.04)\n",
        "\n",
        "    # Threshold the corners to keep only strong ones\n",
        "    corners_thresh = 0.1 * corners.max()\n",
        "    corner_img = np.zeros_like(gray_frame)\n",
        "    corner_img[corners > corners_thresh] = 255\n",
        "\n",
        "    # Find centroids of the detected corners\n",
        "\n",
        "    labeled_image, label_count = custom_connected_components(np.uint8(corner_img))\n",
        "\n",
        "    # Draw the corners on the original frame with larger circles\n",
        "    verified_corners = []\n",
        "    for label in range(1, label_count + 1):\n",
        "        label_coords = np.column_stack(np.where(labeled_image == label))\n",
        "\n",
        "        # Check if there are any coordinates for the current label\n",
        "        if label_coords.size == 0:\n",
        "            continue\n",
        "\n",
        "        centroid = np.mean(label_coords, axis=0).astype(int)\n",
        "        x, y = centroid\n",
        "\n",
        "        # Check if the corner is within the ROI\n",
        "        if roi_x_min < x < roi_x_max and roi_y_min < y < roi_y_max:\n",
        "            close_corners = np.linalg.norm(label_coords - centroid, axis=1) < 20\n",
        "            if np.sum(close_corners) == 1:\n",
        "                cv2.circle(frame, (x, y), 10, (0, 0, 255), -1)  # Larger green circles\n",
        "                verified_corners.append((x, y))\n",
        "\n",
        "\n",
        "\n",
        "    # Draw lines forming a bounding box around the paper\n",
        "    if len(verified_corners) == 4:\n",
        "        cv2.line(frame, tuple(verified_corners[0]), tuple(verified_corners[1]), (255, 0, 0), 2)\n",
        "        cv2.line(frame, tuple(verified_corners[1]), tuple(verified_corners[3]), (255, 0, 0), 2)\n",
        "        cv2.line(frame, tuple(verified_corners[2]), tuple(verified_corners[3]), (255, 0, 0), 2)\n",
        "        cv2.line(frame, tuple(verified_corners[2]), tuple(verified_corners[0]), (255, 0, 0), 2)\n",
        "\n",
        "    # Save the frame with verified corners and overlays as a frame in the output video\n",
        "    if len(verified_corners) == 4:\n",
        "        out.write(frame)"
      ],
      "metadata": {
        "id": "_Q06KLc3pEvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This loop processes each frame from the input video, applies various image processing techniques, and writes frames with verified corners to the output video.\n",
        "\n",
        "Block 9: Release Video Capture and Writer"
      ],
      "metadata": {
        "id": "SoKASUCjpIMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Output video generated successfully at {output_video_path} with {fps_output} fps.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbOFvUFWpKHR",
        "outputId": "95f5752e-91b3-4f18-b122-4943e33df648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output video generated successfully at output_video.mp4 with 5 fps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: This block releases the VideoCapture and VideoWriter objects and prints a success message.\n",
        "\n"
      ],
      "metadata": {
        "id": "gkUbO6G_pMcw"
      }
    }
  ]
}